{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "27582058-4105-4bf5-9e45-7837fdaf12d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data analysis libraries\n",
    "import pandas as pd\n",
    "\n",
    "## Web Scraping libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f9dd195-629d-4aeb-b5dd-3ff7d22a6a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Following: https://www.geeksforgeeks.org/scrape-linkedin-using-selenium-and-beautiful-soup-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f29bec40-5464-44fc-b1bc-7f820a682930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a webdriver instance\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "17c7939f-2e83-472a-af76-1fafe3fbc5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening linkedIn's login page\n",
    "driver.get(\"https://linkedin.com/uas/login\")\n",
    "\n",
    "# waiting for the page to load\n",
    "time.sleep(5)\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e73a29-94f7-4eb9-a5fe-5bafeec278cf",
   "metadata": {},
   "source": [
    "### Login through the browser...\n",
    "\n",
    "We could programmatically enter our credentials with something like the below\n",
    "\n",
    "```python\n",
    "username = driver.find_element(By.ID, \"username\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "592d1501-8aa7-4cdf-a1ed-0a3da08eb0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the jobs URL\n",
    "jobs_url = \"https://www.linkedin.com/jobs/\"\n",
    "\n",
    "driver.get(jobs_url)        # this will open the link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5293f0-9ad5-4f5a-8053-5e5c71d084ca",
   "metadata": {},
   "source": [
    "### Search for IDs in the page:\n",
    "\n",
    "```python\n",
    "ids = driver.find_elements(By.XPATH, '//*[@id]')\n",
    "\n",
    "for ii in ids:\n",
    "    print('Tag:  ' + ii.tag_name)\n",
    "    print('ID:  ' + ii.get_attribute('id'))\n",
    "    print('Name:  ' + str(ii.get_attribute('name')))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b92d53cc-7ab9-4b3e-bab7-5055ebef03b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ids = driver.find_elements(By.XPATH, '//*[@id]')\n",
    "\n",
    "#for ii in ids:\n",
    "#    print('Tag:  ' + ii.tag_name)\n",
    "#    print('ID:  ' + ii.get_attribute('id'))\n",
    "#    print('Name:  ' + str(ii.get_attribute('name')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "332ecb70-06ff-48e7-b94f-3521175a87fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering search term\n",
    "search_term = driver.find_element(By.ID, \"jobs-search-box-keyword-id-ember24\")\n",
    "search_term.send_keys(\"data_scientist\") \n",
    "#elem = driver.find_element(By.ID, \"jobs-search-box-keyword-id-ember24\")\n",
    "#elem.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "292c6bba-d633-4d85-8768-59a2c0e08777",
   "metadata": {},
   "outputs": [],
   "source": [
    "elem = driver.find_element(By.ID, \"jobs-search-box-keyword-id-ember24\")\n",
    "elem.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d7095a7c-aab4-4bcb-9b08-913966d4b594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jobs-search-box-location-id-ember24\n",
    "#location_term = driver.find_element(By.ID, \"jobs-search-box-location-id-ember24\") \n",
    "#location_term.clear()\n",
    "#location_term.send_keys(\"New York, United States\")\n",
    "#location_term.send_keys(Keys.RETURN)\n",
    "#location_term.send_keys(\"New York, United States\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddbc8a0-9e79-4087-b0c2-31db76c6f335",
   "metadata": {},
   "source": [
    "### Parse the search results page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3d5ae4c4-3bf5-42bd-960d-ec0800a62b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_page_of_listings(soup):\n",
    "\n",
    "\n",
    "    job_ids = []\n",
    "    job_titles = []\n",
    "    job_company = []\n",
    "    job_location = []\n",
    "    job_salaries = []\n",
    "    \n",
    "    for tag in soup.find_all(class_=\"job-card-list\"):\n",
    "        job_ids.append(tag.get('data-job-id'))\n",
    "        (job_titles.append(soup.find('div', {'data-job-id': tag.get('data-job-id')})\n",
    "                           .find('a', {'class': 'job-card-list__title'}).text.strip()))\n",
    "        ## The company for the job is under the job-card-container__primary-description\n",
    "        (job_company.append(soup.find('div', {'data-job-id': tag.get('data-job-id')})\n",
    "                            .find('span', {'class': 'job-card-container__primary-description'}).text.strip()))\n",
    "        ## The first item in the metadata is typically the job location:\n",
    "        (job_location.append(soup.find('div', {'data-job-id': tag.get('data-job-id')})\n",
    "                           .find('li', {'class': 'job-card-container__metadata-item'}).text.strip())) \n",
    "        ## The second item in the list, if present, will be the salary\n",
    "        try:\n",
    "            job_salary = (soup.find('div', {'data-job-id': tag.get('data-job-id')})\n",
    "                               .find_all('li', {'class': 'job-card-container__metadata-item'})[1].text.strip())\n",
    "            if \"$\" in job_salary: # if the second metadata point has a dollar sign\n",
    "                if \"-\" in job_salary:  # If it's a salary range\n",
    "                    # strip everything after the second \"/yr\"\n",
    "                    job_salaries.append(\"\".join(job_salary.split(\"/yr\", 2)[:2]))\n",
    "                if (\"-\" not in job_salary) and \"yr\" in job_salary:\n",
    "                    # strip everything after the first \"/yr\"\n",
    "                    job_salaries.append(\"\".join(job_salary.split(\"/yr\", 2)[:2]))\n",
    "            else:\n",
    "                job_salaries.append(\"No_Salary_Listed\")\n",
    "        except IndexError:\n",
    "            job_salaries.append(\"No_Salary_Listed\")\n",
    "\n",
    "    job_listings = pd.DataFrame(list(zip(job_ids, job_titles, job_company, job_location, job_salaries)),\n",
    "               columns =['Job_ID', 'Title', 'Company', 'Location', 'Salary'])\n",
    "    return job_listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "61f9ae51-d621-454a-bbef-d830fb048ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = driver.page_source\n",
    "\n",
    "# Now using beautiful soup\n",
    "soup = BeautifulSoup(src, \"html.parser\")\n",
    "\n",
    "job_listings = assemble_page_of_listings(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "49009acc-37e8-46c2-bbbe-f9089d8c257b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3722171802</td>\n",
       "      <td>Data Scientist, Lead</td>\n",
       "      <td>Booz Allen Hamilton</td>\n",
       "      <td>Norfolk, VA (Remote)</td>\n",
       "      <td>$106K - $242K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3725737021</td>\n",
       "      <td>Sr. Staff Data Scientist, Ecosystem</td>\n",
       "      <td>Pinterest</td>\n",
       "      <td>California, United States (Remote)</td>\n",
       "      <td>No_Salary_Listed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3718232807</td>\n",
       "      <td>Senior Staff Data Scientist</td>\n",
       "      <td>Coupang</td>\n",
       "      <td>Seattle, WA (Hybrid)</td>\n",
       "      <td>$170K - $318K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3725128742</td>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>Fanatics</td>\n",
       "      <td>New York, NY (On-site)</td>\n",
       "      <td>$190K - $225K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3713421109</td>\n",
       "      <td>Data Scientist Analyst - Early Career</td>\n",
       "      <td>Lockheed Martin</td>\n",
       "      <td>Fort Worth, TX</td>\n",
       "      <td>No_Salary_Listed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3724802079</td>\n",
       "      <td>Principal Data Scientist, The Lab</td>\n",
       "      <td>Capital One</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>No_Salary_Listed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3730760978</td>\n",
       "      <td>Sr. Program Manager, Tech (Chief of Staff) - P...</td>\n",
       "      <td>Uber</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>$140K - $172K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Job_ID                                              Title  \\\n",
       "0  3722171802                               Data Scientist, Lead   \n",
       "1  3725737021                Sr. Staff Data Scientist, Ecosystem   \n",
       "2  3718232807                        Senior Staff Data Scientist   \n",
       "3  3725128742                                 Sr. Data Scientist   \n",
       "4  3713421109              Data Scientist Analyst - Early Career   \n",
       "5  3724802079                  Principal Data Scientist, The Lab   \n",
       "6  3730760978  Sr. Program Manager, Tech (Chief of Staff) - P...   \n",
       "\n",
       "               Company                            Location            Salary  \n",
       "0  Booz Allen Hamilton                Norfolk, VA (Remote)     $106K - $242K  \n",
       "1            Pinterest  California, United States (Remote)  No_Salary_Listed  \n",
       "2              Coupang                Seattle, WA (Hybrid)     $170K - $318K  \n",
       "3             Fanatics              New York, NY (On-site)     $190K - $225K  \n",
       "4      Lockheed Martin                      Fort Worth, TX  No_Salary_Listed  \n",
       "5          Capital One                   San Francisco, CA  No_Salary_Listed  \n",
       "6                 Uber                         Seattle, WA     $140K - $172K  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_listings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552c46d1-5af2-4d14-9842-2c04927a580f",
   "metadata": {},
   "source": [
    "### Click into an individual Item\n",
    "\n",
    "```python\n",
    "clickable = driver.findElement(By.id(\"clickable\"));\n",
    "clickable.click()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2db057-1d44-41b0-857d-e0f3954ef705",
   "metadata": {},
   "source": [
    "## Go to each page and get the job text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c1e23f-b02c-4862-8d55-8413def9caf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the jobs URL\n",
    "jobs_url = \"https://www.linkedin.com/jobs/\"\n",
    "\n",
    "driver.get(jobs_url)        # this will open the link"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
